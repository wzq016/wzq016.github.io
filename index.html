<!DOCTYPE HTML>
<html lang="en">
  <head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-R5VLJ0XBY6"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-R5VLJ0XBY6');
    </script>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Ziqi Wang</title>

    <meta name="author" content="Ziqi Wang">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <!-- <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ü§îÔ∏è</text></svg>"> -->
    <!-- <link rel="icon" href="images/universe.jpeg"> -->
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Ziqi Wang (ÁéãÂ≠êÂ•á)
                </p>
                <!-- <p style="color:tomato;">
                  This website is currently under construction.
                </p> -->
                <p>I am a Ph.D. student at the University of Illinois Urbana-Champaign, advised by <a href="http://blender.cs.illinois.edu/hengji.html">Prof. Heng Ji</a> and <a href="https://tongzhang-ml.org/">Prof. Tong Zhang</a>.
                </p>
                <p>
                  I was a part-time intern at <a href="https://yutori.com/">Yutori</a> in 2025 spring. I also interned at Meta GenAI in 2024 Summer, working with <a href="https://ai.meta.com/people/7558226144216020/rui-wang/">Rui Wang</a>. In 2022 and 2023, I spent two summers at Google working with <a href="https://crickwu.github.io/">Dr. Crick Wu</a> and <a href="https://www.le-hou.com/">Dr. Le Hou</a>. Prior to my Ph.D. study, I obtained a Bachelor's Degree in Computer Science at Tsinghua University, where I was fortunate to work with <a href="http://nlp.csai.tsinghua.edu.cn/~lzy">Prof. Zhiyuan Liu</a>, <a href="http://www.xlhu.cn/">Prof. Xiaolin Hu</a>, <a href="http://coai.cs.tsinghua.edu.cn/hml">Prof. Minlie Huang</a>, and <a href="https://shanzhenren.github.io/">Prof. Xiang Ren</a> at the University of Southern California.
                </p>
                <p style="text-align:center">
                  <a href="mailto:wzq016@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=xYRZiZkAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/wzq016">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/ziqi-wang-0432621a7/">Linkedin</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/profile.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/profile_circle.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  My research goal is to empower AI with strong reasoning capabilities to help human solve real-world problems reliably, and eventually boost science discovery process. My current milestone is to investigate:
                </p>
                <p>
                  (1) the intrinsic bottleneck of AI reasoning, from both architecture and algorithm perspectives. <a href="https://arxiv.org/abs/2407.01100">[ICLR 2025]</a>
                </p>
                <p>
                  (2) Improving AI reasoning through post-training, especially from the aspect of reinforcement learning. <a href="https://arxiv.org/abs/2310.00898">[ICLR 2024]</a> <a href="https://arxiv.org/abs/2505.02387">[Preprint 2025]</a>
                </p>
                <p>
                  Previously, I worked on representation learning and neuro-symbolic learning during my undergraduate study.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <h2>Selected Publications (See full list on <a href="https://scholar.google.com/citations?user=xYRZiZkAAAAJ&hl=en"><h2 style="display: inline">Google Scholar</h2></a>)</h2>
          <p>
            * denotes equal contribution
          </p>
        </td>
        </tr>
      </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      
      <tr>
        <td style="padding:20px;width:35%;vertical-align:middle;max-width: 35%;">
            <img src='images/rmr1.png' width="100%">
        </td>
        <td style="padding:20px;width:65%;vertical-align:middle">
          <a href="https://arxiv.org/pdf/2505.02387">
            <span class="papertitle">RM-R1: Reward Modeling as Reasoning</span>
          </a>
          <br>
          <a href="https://xiusic.github.io/">Xiusi Chen*</a>,
          <a href="https://gaotangli.github.io/">Gaotang Li*</a>,
          <strong>Ziqi Wang*</strong>,
          And other 9 authors.
          <br>
          <em>Preprint</em>, 2025 &nbsp;
          <br>
          <a href="https://arxiv.org/pdf/2505.02387">Paper</a>
          <p></p>
          <p>
          Reward model with thinking improves the rewards accuracy.
          </p>
        </td>
      </tr>

      <tr>
        <td style="padding:20px;width:35%;vertical-align:middle;max-width: 35%;">
            <img src='images/pine.png' width="100%">
        </td>
        <td style="padding:20px;width:65%;vertical-align:middle">
          <a href="https://arxiv.org/abs/2407.01100">
            <span class="papertitle">Eliminating Position Bias of Language Models: A Mechanistic Approach</span>
          </a>
          <br>
          <strong>Ziqi Wang</strong>,
          <a href="https://hanlin-zhang.com/">Hanlin Zhang</a>,
          <a href="https://people.tamu.edu/~lxe/">Xiner Li</a>,
          <a href="https://khhuang.me/">Kuan-Hao Huang</a>,
          <a href="https://glaciohound.github.io/">Chi Han</a>,
          <a href="https://people.tamu.edu/~sji/">Shuiwang Ji</a>,
          <a href="https://sham.seas.harvard.edu/">Sham M. Kakade</a>,
          <a href="https://haopeng-nlp.github.io/">Hao Peng</a>,
          <a href="http://blender.cs.illinois.edu/hengji.html">Heng Ji</a>
          <br>
          <em>ICLR</em>, 2025 &nbsp;
          <br>
          <a href="https://arxiv.org/abs/2407.01100">Paper</a>
          /
          <a href="https://x.com/wzq016/status/1808568703229046792">Twitter</a>
          <p></p>
          <p>
          We propose a method to eliminate the position bias in LMs, which help LMs to better conduct reasoning.
          </p>
        </td>
      </tr>

      <!-- <tr>
        <td style="padding:20px;width:35%;vertical-align:middle;max-width: 35%;">
            <img src='images/idpo.png' width="100%">
        </td>
        <td style="padding:20px;width:65%;vertical-align:middle">
          <a href="https://arxiv.org/abs/2407.01100">
            <span class="papertitle">Iterative Preference Learning from Human Feedback: Bridging Theory and Practice for RLHF under KL-Constraint</span>
          </a>
          <br>
          <a href="https://weixiongust.github.io/WeiXiongUST/index.html">Wei Xiong*</a>,
          <a href="https://hendrydong.github.io/">Hanze Dong*</a>,
          <a href="https://chenluye99.github.io/">Chenlu Ye*</a>,
          <strong>Ziqi Wang</strong>,
          <a href="https://hanzhong-ml.github.io/">Han Zhong</a>,
          <a href="http://blender.cs.illinois.edu/hengji.html">Heng Ji</a>,
          <a href="https://nanjiang.cs.illinois.edu/">Nan Jiang</a>,
          <a href="https://tongzhang-ml.org/">Tong Zhang</a>
          <br>
          <em>ICML</em>, 2024; <em>ICLR ME-FoMo</em>, 2024 &nbsp; <font color="red"><strong>(Oral Presentation)</strong></font>
          <br>
          <a href="https://arxiv.org/abs/2312.11456">Paper</a>
          /
          <a href="https://x.com/wzq016/status/1808568703229046792">Twitter</a>
          <p></p>
          <p>
          On-Policy matters for Direct Policy Optimization!
          </p>
        </td>
      </tr> -->
      
          <tr>
        <td style="padding:20px;width:35%;vertical-align:middle;max-width: 35%;">
            <img src='images/pit.png' width="100%">
        </td>
        <td style="padding:20px;width:65%;vertical-align:middle">
          <a href="https://arxiv.org/abs/2310.00898">
            <span class="papertitle">Enabling Language Models to Implicitly Learn Self-Improvement</span>
          </a>
          <br>
          <strong>Ziqi Wang</strong>,
          <a href="https://www.le-hou.com/">Le Hou</a>,
          <a href="https://scholar.google.com/citations?user=eWEj9g0AAAAJ&hl=en">Tianjian Lu</a>,
          <a href="https://crickwu.github.io/">Yuexin Wu</a>,
          <a href="https://scholar.google.com/citations?user=Nun8Dy0AAAAJ&hl=en&authuser=1">Yunxuan Li</a>,
          <a href="https://scholar.google.com/citations?user=kgE6J2AAAAAJ&hl=en">Hongkun Yu</a>,
          <a href="http://blender.cs.illinois.edu/hengji.html">Heng Ji</a>
          <br>
          <em>ICLR</em>, 2024 &nbsp;
          <br>
          <a href="https://arxiv.org/abs/2310.00898">Paper</a>
          /
          <a href="https://docs.google.com/presentation/d/1LANKh4s_FEnu_OudrW3Dr_vQJL7E6erUnzhrA-7WKk8/edit?usp=sharing">Slides</a>
          /
          <a href="https://twitter.com/wzq016/status/1709077188962570420">Twitter</a>
          <p></p>
          <p>
          Teaching models self-improvement with reinforcement learning.
          </p>
        </td>
      </tr>

      <!-- <tr>
        <td style="padding:20px;width:35%;vertical-align:middle;max-width: 35%;">
            <img src='images/augpro.png' width="100%">
        </td>
        <td style="padding:20px;width:65%;vertical-align:middle">
          <a href="https://arxiv.org/abs/2210.11768">
            <span class="papertitle">Augmentation with Projection: Towards an Effective and Efficient Data Augmentation Paradigm for Distillation</span>
          </a>
          <br>
          <strong>Ziqi Wang</strong>,
          <a href="https://crickwu.github.io/">Yuexin Wu</a>,
          <a href="https://frederick0329.github.io/">Frederick Liu</a>,
          <a href="https://daogaoliu.github.io/">Daogao Liu</a>,
          <a href="https://www.le-hou.com/">Le Hou</a>,
          <a href="https://scholar.google.com/citations?user=kgE6J2AAAAAJ&hl=en">Hongkun Yu</a>,
          <a href="https://www.linkedin.com/in/jing-li-b2558a5a/">Jing Li</a>,
          <a href="http://blender.cs.illinois.edu/hengji.html">Heng Ji</a>
          <br>
          <em>ICLR</em>, 2023 &nbsp;
          <br>
          <a href="https://arxiv.org/abs/2210.11768">Paper</a>
          /
          <a href="data/augpro.pptx">Slides</a>
          /
          <a href="https://iclr.cc/virtual/2023/poster/11029">Talk Recording</a>
          /
          <a href="https://docs.google.com/presentation/d/1xjYc1nk2mZgmNJoV4KFjLUVLdPwiTaWw/edit?usp=sharing&ouid=115672715451044813452&rtpof=true&sd=true">Poster</a>
          <p></p>
          <p>
            We propose a simple data augmentation method that benefit knowledge distillation in a data-efficient regime.
          </p>
        </td>
      </tr>


      <tr>
        <td style="padding:20px;width:35%;vertical-align:middle;max-width: 35%;">
            <img src='images/adv.png' width="100%">
        </td>
        <td style="padding:20px;width:65%;vertical-align:middle">
          <a href="https://arxiv.org/abs/2212.01806">
            <span class="papertitle">Recognizing Object by Components With Human Prior Knowledge Enhances Adversarial Robustness of Deep Neural Networks</span>
          </a>
          <br>
          <a href="https://scholar.google.com/citations?user=Is24dqwAAAAJ&hl=en&oi=sra">Xiao Li*</a>,
          <strong>Ziqi Wang*</strong>,
          <a href="https://www.cs.tsinghua.edu.cn/csen/info/1059/4006.htm">Bo Zhang</a>,
          <a href="https://scholar.google.com/citations?user=DbviELoAAAAJ&hl=en">Fuchun Sun</a>,
          <a href="http://www.xlhu.cn/">Xiaolin Hu</a>
          <br>
          <em>TPAMI</em>, 2023 &nbsp;
          <br>
          <a href="https://arxiv.org/abs/2212.01806">Paper</a>
          /
          <a href="https://github.com/LixiaoTHU/ROCK">Code</a>
          <p></p>
          <p>
          We reveal that human prior knowledge can serve as an important component to improve vision robustness to attacks.
          </p>
        </td>
      </tr>


      <tr>
        <td style="padding:20px;width:35%;vertical-align:middle;max-width: 35%;">
            <img src='images/cleve.png' width="100%">
        </td>
        <td style="padding:20px;width:65%;vertical-align:middle">
          <a href="https://arxiv.org/abs/2105.14485">
            <span class="papertitle">CLEVE: Contrastive Pre-training for Event Extraction</span>
          </a>
          <br>
          <strong>Ziqi Wang*</strong>,
          <a href="https://bakser.github.io/">Xiaozhi Wang*</a>,
          <a href="https://thucsthanxu13.github.io/">Xu Han</a>,
          <a href="https://linyankai.github.io/">Yankai Lin</a>,
          <a href="https://scholar.google.ca/citations?user=YnIq4hsAAAAJ&hl=en">Lei Hou</a>,
          <a href="https://nlp.csai.tsinghua.edu.cn/~lzy/">Zhiyuan Liu</a>,
          <a href="https://www.lpeng.net/">Peng Li</a>,
          <a href="http://keg.cs.tsinghua.edu.cn/persons/ljz/">Juanzi Li</a>,
          <a href="https://dblp.org/pid/00/5012-16.html">Jie Zhou</a>
          <br>
          <em>ACL</em>, 2021 &nbsp;
          <br>
          <a href="https://arxiv.org/abs/2105.14485">Paper</a>
          /
          <a href="data/CLEVE.pdf">Slides</a>
          /
          <a href="https://underline.io/lecture/25941-cleve-contrastive-pre-training-for-event-extraction">Talk Recording</a>
          /
          <a href="https://github.com/THU-KEG/CLEVE">Code</a>
          <p></p>
          <p>
          We show that event-oriented contrastive pre-training can enhance event representations and understanding.
          </p>
        </td>
      </tr>


      <tr>
        <td style="padding:20px;width:35%;vertical-align:middle;max-width: 35%;">
            <img src='images/next.png' width="100%">
        </td>
        <td style="padding:20px;width:65%;vertical-align:middle">
          <a href="https://arxiv.org/abs/1911.01352">
            <span class="papertitle">Learning from Explanations with Neural Execution Tree</span>
          </a>
          <br>
          <strong>Ziqi Wang*</strong>,
          <a href="https://yujia-qin.github.io/">Yujia Qin*</a>,
          <a href="https://wzhouad.github.io/">Wenxuan Zhou</a>,
          <a href="https://junyann.github.io/">Jun Yan</a>,
          <a href="http://yeqy.xyz/">Qinyuan Ye</a>,
          <a href="https://scholar.google.com/citations?user=cJwZx6IAAAAJ&hl=en">Leonardo Neves</a>,
          <a href="https://nlp.csai.tsinghua.edu.cn/~lzy/">Zhiyuan Liu</a>,
          <a href="https://shanzhenren.github.io/">Xiang Ren</a>
          <br>
          <em>ICLR</em>, 2020 &nbsp;
          <br>
          <a href="https://arxiv.org/abs/1911.01352">Paper</a>
          /
          <a href="https://inklab.usc.edu/project-NExT/">Project Website</a>
          /
          <a href="data/next.pptx">Slides</a>
          /
          <a href="https://papertalk.org/papertalks/3963">Talk Recording</a>
          /
          <a href="https://github.com/INK-USC/NExT">Code</a>
          <p></p>
          <p>
          We propose to use human explanations to build neuro-symbolic networks. The networks can then label pseudo labels to improve semi-supervised training.
          </p>
        </td>
      </tr>

      <tr>
        <td style="padding:20px;width:35%;vertical-align:middle;max-width: 35%;">
            <img src='images/nero.png' width="100%">
        </td>
        <td style="padding:20px;width:65%;vertical-align:middle">
          <a href="https://arxiv.org/pdf/1909.02177.pdf">
            <span class="papertitle">NERO: A Neural Rule Grounding Framework for Label-Efficient Relation Extraction</span>
          </a>
          <br>
          <a href="https://wzhouad.github.io/">Wenxuan Zhou</a>,
          <a href="https://www.linkedin.com/in/hongtao-lin/">Hongtao Lin</a>,
          <a href="https://yuchenlin.xyz/">Yuchen Lin</a>,
          <strong>Ziqi Wang</strong>,
          <a href="https://scholar.google.com/citations?user=Z2d0glgAAAAJ&hl=en">Junyi Du</a>,
          <a href="https://scholar.google.com/citations?user=cJwZx6IAAAAJ&hl=en">Leonardo Neves</a>,
          <a href="https://shanzhenren.github.io/">Xiang Ren</a>
          <br>
          <em>WWW</em>, 2020 &nbsp; <font color="red"><strong>(Best Paper Runner-Up, 2/1500+)</strong></font>
          <br>
          <a href="https://arxiv.org/pdf/1909.02177.pdf">Paper</a>
          /
          <a href="https://github.com/INK-USC/NERO">Code</a>
          <p></p>
          <p>
          We propose to use neural rules to ground data-efficient learning in relation extraction.
          </p>
        </td>
      </tr>

      <tr>
        <td style="padding:20px;width:35%;vertical-align:middle;max-width: 35%;">
            <img src='images/hmeae.png' width="100%">
        </td>
        <td style="padding:20px;width:65%;vertical-align:middle">
          <a href="https://aclanthology.org/D19-1584/">
            <span class="papertitle">HMEAE: Hierarchical Modular Event Argument Extraction</span>
          </a>
          <br>
          <a href="https://bakser.github.io/">Xiaozhi Wang*</a>,
          <strong>Ziqi Wang*</strong>,
          <a href="https://thucsthanxu13.github.io/">Xu Han</a>,
          <a href="https://nlp.csai.tsinghua.edu.cn/~lzy/">Zhiyuan Liu</a>,
          <a href="http://keg.cs.tsinghua.edu.cn/persons/ljz/">Juanzi Li</a>,
          <a href="https://www.lpeng.net/">Peng Li</a>,
          <a href="https://scholar.google.com/citations?user=zIgT0HMAAAAJ&hl=en">Maosong Sun</a>,
          <a href="https://dblp.org/pid/00/5012-16.html">Jie Zhou</a>,
          <a href="https://shanzhenren.github.io/">Xiang Ren</a>
          <br>
          <em>EMNLP-IJCNLP</em>, 2019 &nbsp; <font color="red"><strong>(Oral Presentation)</strong></font>
          <br>
          <a href="https://aclanthology.org/D19-1584/">Paper</a>
          /
          <a href="data/HMEAE.pdf">Slides</a>
          /
          <a href="https://www.youtube.com/watch?v=TNc87GfWmzg">Talk Recording</a>
          /
          <a href="https://github.com/thunlp/HMEAE">Code</a>
          <p></p>
          <p>
          We use human prior knowledge to make models aware of the semantic relations between labels and thus perform better in the event argument extraction task.
          </p>
        </td>
      </tr> -->

          </tbody></table>

          
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Education</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle;max-width:25%"><img src="images/uiuc.jpg" width="100%" max-width="100%"></td>
              <td width="75%" valign="center">
                University of Illinois Urbana-Champaign
              <br>
                Ph.D. in Computer Science, 2021-2025
              <br>
              <br>
                Advisor: <a href="http://blender.cs.illinois.edu/hengji.html">Prof. Heng Ji</a> and <a href="https://tongzhang-ml.org/">Prof. Tong Zhang</a>
              </td>
            </tr>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle;max-width:25%"><img src="images/tsinghua.jpg" width="100%" max-width="100%"></td>
              <td width="75%" valign="center">
                Tsinghua University
              <br>
              B.E. in Computer Science, 2016-2021
              <br>
              <br>
                Advisor: <a href="http://nlp.csai.tsinghua.edu.cn/~lzy">Prof. Zhiyuan Liu</a>, <a href="http://www.xlhu.cn/">Prof. Xiaolin Hu</a>, and <a href="http://coai.cs.tsinghua.edu.cn/hml">Prof. Minlie Huang</a>
              </td>
            </tr>
            
          </tbody></table>

          <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Service</h2>
                <br>
                Reviewer: ICLR, NeurIPS (<font color="red"><strong>Top reviewer in 2024</strong></font>), ICML, ACL, EMNLP, NAACL, Pattern Recognition
              </td>
            </tr>
          </tbody></table> -->

          <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Talks</h2>
                <br>
                Teaching LMs to Self-Improve by Reinforcement Learning. <a href="https://cohere.com/research">Cohere AI</a>, 2024. [<a href="https://docs.google.com/presentation/d/1i9mahyIAOK23YYjZiGamLXdxC4zWU69TkEkjEZpnRNA/edit?usp=sharing">Slides</a>][<a href="https://www.youtube.com/watch?v=HwoK0eggOzw">Video</a>]
                <br>
                Enabling Language Models to Implicitly Learn Self-Improvement. <a href="https://www.objective.inc/">Objective, Inc.</a>, 2023. [<a href="https://docs.google.com/presentation/d/1i9mahyIAOK23YYjZiGamLXdxC4zWU69TkEkjEZpnRNA/edit?usp=sharing">Slides</a>]
              </td>
            </tr>
          </tbody></table> -->

          <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Projects</h2>
                <br>
                In addition to my research work, I find pleasure in coding. I develop websites, applications, and other software programs. Although some of my previous projects have been lost over time, I have managed to archive several of them.
                </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:35%;vertical-align:middle;max-width: 35%;">
                <img src='images/covid_list.png' width="100%">
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
              <a href="https://blenderdemo.com/covid-list">
                <span class="papertitle">COVID-19 Claim Radar: A Structured Claim Extraction and Tracking System</span>
              </a>
              <p>Built with <a href="https://go.dev/">Go</a> and <a href="https://vuejs.org/">Vue.js</a>.</p>
              <a href="https://blenderdemo.com/covid-list">Demo</a>
              /
              <a href="https://github.com/blender-nlp/covid-claim-radar/tree/main/demo">Code</a>
              <p></p>
              <p>
                A web interface that shows claims about COVID-19 crawled from the Internet. The system details can be found in this <a href="https://aclanthology.org/2022.acl-demo.13/">paper</a>, which is accepted at ACL 2022 (System Demonstration), and the <a href="https://github.com/blender-nlp/covid-claim-radar">implementation</a>.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:35%;vertical-align:middle;max-width: 35%;">
                <img src='images/smartbook.png' width="100%">
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
              <a href="https://blenderdemo.com/smartbook">
                <span class="papertitle">SmartBook: AI-Assisted Situation Report Generation</span>
              </a>
              <p>Built with <a href="https://vuejs.org/">Vue.js</a>.</p>
              <a href="https://blenderdemo.com/smartbook">Demo</a>
              /
              <a href="https://github.com/wzq016/SmartBookDemo">Code</a>
              <p></p>
              <p>
                A web interface that shows situation reports generated by AI. The system details can be found in this <a href="https://arxiv.org/abs/2303.14337">paper</a> and the <a href="https://github.com/blender-nlp/SmartBook">implementation</a>.
              </p>
            </td>
          </tr> -->

          <!-- <tr>
            <td style="padding:20px;width:35%;vertical-align:middle;max-width: 35%;">
                <img src='images/covidapp.png' width="100%">
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
              <a href="https://github.com/wzq016/COVID-NewsApp">
                <span class="papertitle">COVID-19 News App for Android</span>
              </a>
              <p>Built with <a href="https://www.java.com/">Java</a>.</p>
              <a href="https://github.com/wzq016/COVID-NewsApp">Code</a>
              <p></p>
              <p>
                This Android app shows COVID-19 news (Internet connection is needed).
              </p>
            </td>
          </tr> -->

        <!-- </tbody></table> -->

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
                <br>
                I was a Physics student before, and I am still interested in Physics and Astronomy nowadays. I enjoy understanding and creation, therefore enjoying activities such as repairment. I am deeply inspired by <a href="https://en.wikipedia.org/wiki/John_Carmack">John Carmack</a> and learn a lot of life advice from <a href="https://twitter.com/elonmusk">Elon Musk</a>. There are three lessons that left extemely deep impression on me since they truly show the fun of learning: Fundamentals of Physics taught by <a href="https://www.phys.tsinghua.edu.cn/phyen/info/1071/1253.htm">Shuo Jiang</a>, Calculus taught by <a href="https://www.tcm.tsinghua.edu.cn/info/1003/1032.htm">Yinghua Ai</a>, and Real Analysis taught by <a href="https://www.researchgate.net/profile/Xuguang-Lu-2">Xuguang Lu</a>.
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:center;font-size:small;">
                  The website is adapted from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>. Last update: Jul, 2025.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
